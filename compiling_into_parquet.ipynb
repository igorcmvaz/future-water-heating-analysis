{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da3b7dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lidos 50/624 arquivos...\n",
      "Lidos 100/624 arquivos...\n",
      "Lidos 150/624 arquivos...\n",
      "Lidos 200/624 arquivos...\n",
      "Lidos 250/624 arquivos...\n",
      "Lidos 300/624 arquivos...\n",
      "Lidos 350/624 arquivos...\n",
      "Lidos 400/624 arquivos...\n",
      "Lidos 450/624 arquivos...\n",
      "Lidos 500/624 arquivos...\n",
      "Lidos 550/624 arquivos...\n",
      "Lidos 600/624 arquivos...\n",
      "Lidos 624/624 arquivos...\n",
      "✅ Consolidado com 3,246,048 linhas em: c:\\Users\\igorc\\Desktop\\DocumentosAT\\Repo Local\\water-heating-analysis\\shower_all.parquet\n",
      "\n",
      "Amostra do resumo por hora/threshold:\n",
      " sim_hour  temp_threshold_c  linhas\n",
      "        0                15    5202\n",
      "        0                16    5202\n",
      "        0                17    5202\n",
      "        0                18    5202\n",
      "        0                19    5202\n",
      "        0                20    5202\n",
      "        0                21    5202\n",
      "        0                22    5202\n",
      "        0                23    5202\n",
      "        0                24    5202\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Consolida CSVs de simulação de chuveiros em um único Parquet.\n",
    "- Lê arquivos no padrão: shower_hHH_tTT_1min.csv (ex.: shower_h00_t15_1min.csv)\n",
    "- Faz parsing de HH (hora) e TT (threshold °C) a partir do nome\n",
    "- Gera um único arquivo .parquet com todos os registros\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# === CONFIGURAÇÕES ===\n",
    "INPUT_DIR = \"Output\"                 # pasta onde estão os CSVs\n",
    "GLOB_PATTERN = \"shower_h*_t*_1min.csv\"\n",
    "OUTPUT_PARQUET = \"shower_all.parquet\"\n",
    "# Se quiser salvar no próprio \"Output\", use: OUTPUT_PARQUET = os.path.join(INPUT_DIR, \"shower_all.parquet\")\n",
    "\n",
    "# Regex para extrair hora e threshold do nome do arquivo\n",
    "FILENAME_RE = re.compile(r\"shower_h(\\d{2})_t(\\d+)_1min\\.csv$\", re.IGNORECASE)\n",
    "\n",
    "# Colunas que certamente são numéricas (ajuste se necessário)\n",
    "NUMERIC_COLS = [\n",
    "    \"latitude\", \"longitude\", \"year\", \"bath_hours\", \"bath_minutes\", \"flow_lpm\", \"efficiency\",\n",
    "    \"temp_limit_c\", \"temp_usage_target_c\", \"consumo_anual_kwh\", \"consumo_dia_max_kwh\",\n",
    "    \"required_kw_p95\", \"nominal_kw_p95\", \"required_kw_max\", \"nominal_kw_max\"\n",
    "]\n",
    "\n",
    "def parse_from_filename(path: str):\n",
    "    \"\"\"Retorna (hour, threshold) extraídos do nome do arquivo.\"\"\"\n",
    "    name = os.path.basename(path)\n",
    "    m = FILENAME_RE.search(name)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Arquivo fora do padrão esperado: {name}\")\n",
    "    hour = int(m.group(1))\n",
    "    threshold = int(m.group(2))\n",
    "    return hour, threshold\n",
    "\n",
    "def read_csv_safe(path: str) -> pd.DataFrame:\n",
    "    \"\"\"Lê CSV com fallback de encoding e tipos.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(path, low_memory=False)\n",
    "    except UnicodeDecodeError:\n",
    "        df = pd.read_csv(path, low_memory=False, encoding=\"latin-1\")\n",
    "\n",
    "    # Normaliza nomes de colunas (tira espaços/brancos, mantém case original)\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "\n",
    "    # Converte colunas numéricas conhecidas quando existirem\n",
    "    for col in NUMERIC_COLS:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    # Alguns campos de texto podem vir como numéricos por engano; força para string onde faz sentido\n",
    "    for text_col in [\"city\", \"state\", \"scenario\", \"temp_usage_mode\", \"power_selection\"]:\n",
    "        if text_col in df.columns:\n",
    "            df[text_col] = df[text_col].astype(str).str.strip()\n",
    "\n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    input_path = os.path.abspath(INPUT_DIR)\n",
    "    files = sorted(glob.glob(os.path.join(input_path, GLOB_PATTERN)))\n",
    "    if not files:\n",
    "        raise SystemExit(f\"Nenhum CSV encontrado em {input_path} com padrão {GLOB_PATTERN}\")\n",
    "\n",
    "    frames = []\n",
    "    for i, f in enumerate(files, 1):\n",
    "        hour, threshold = parse_from_filename(f)\n",
    "        df = read_csv_safe(f)\n",
    "        # adiciona metadados vindos do nome do arquivo\n",
    "        df[\"sim_hour\"] = hour\n",
    "        df[\"temp_threshold_c\"] = threshold\n",
    "        df[\"sim_minutes_per_day\"] = 1  # pelo padrão 1min no nome\n",
    "        df[\"source_file\"] = os.path.basename(f)\n",
    "        frames.append(df)\n",
    "\n",
    "        if i % 50 == 0 or i == len(files):\n",
    "            print(f\"Lidos {i}/{len(files)} arquivos...\")\n",
    "\n",
    "    full = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "    # Ordena colunas: meta primeiro, depois o restante\n",
    "    meta_cols = [\"city\", \"state\", \"latitude\", \"longitude\", \"year\", \"scenario\",\n",
    "                 \"sim_hour\", \"temp_threshold_c\", \"sim_minutes_per_day\", \"source_file\"]\n",
    "    ordered_cols = meta_cols + [c for c in full.columns if c not in meta_cols]\n",
    "    full = full[ordered_cols]\n",
    "\n",
    "    # Tipos finais (onde fizer sentido)\n",
    "    for col in [\"sim_hour\", \"temp_threshold_c\", \"sim_minutes_per_day\", \"year\"]:\n",
    "        if col in full.columns:\n",
    "            full[col] = pd.to_numeric(full[col], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "    # Salva Parquet (único arquivo)\n",
    "    full.to_parquet(OUTPUT_PARQUET, engine=\"pyarrow\", index=False)\n",
    "    print(f\"✅ Consolidado com {len(full):,} linhas em: {os.path.abspath(OUTPUT_PARQUET)}\")\n",
    "\n",
    "    # Pequeno resumo\n",
    "    try:\n",
    "        resumo = (\n",
    "            full.groupby([\"sim_hour\", \"temp_threshold_c\"])\n",
    "                .size()\n",
    "                .rename(\"linhas\")\n",
    "                .reset_index()\n",
    "                .sort_values([\"sim_hour\", \"temp_threshold_c\"])\n",
    "        )\n",
    "        print(\"\\nAmostra do resumo por hora/threshold:\")\n",
    "        print(resumo.head(10).to_string(index=False))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
